[
  {
    "objectID": "develop/teachingmodule.html",
    "href": "develop/teachingmodule.html",
    "title": "Breast Cancer Proteomics Module",
    "section": "",
    "text": "!!! note “Section Overview”"
  },
  {
    "objectID": "develop/teachingmodule.html#preliminary-work",
    "href": "develop/teachingmodule.html#preliminary-work",
    "title": "Breast Cancer Proteomics Module",
    "section": "Preliminary work",
    "text": "Preliminary work\nFor this work, we will use the data that was used and analyzed in the paper Breast cancer quantitative proteome and proteogenomic landscape by Johansson et al., which compares subgroups of breast cancer tumors from the Oslo2 cohort.\nBefore delving into the actual analysis of the data in FragPipe, we must initially:\n\nRead and understand the study design of the paper.\nUnderstand the data being used from the paper.\n\n\nQuestions for Understanding the Paper\nTo better understand the paper, we have formulated some questions that should help clarify the study design, aim, and overall scope of the work. These questions are listed below:\n\n…\n…\n…\n\n\n\nSupplementary Data\nBefore we proceed and download the data available from the paper, we must first delve into some of the details in Supplementary Data 1. This is a large table containing the quantitative proteome data from the Oslo2 breast cancer cohort, which includes 45 subgroups of cancer tumors and relates to Figures 1-6 in the paper.\nTo better understand the supplementary data, we have prepared guiding questions to aid in interpreting the table. You can find the supplementary data in the paper here.\n\n\nQuestion 1: Provide a brief description of the content presented in the table.\n\n\n\n\nQuestion 2: What information does the tumor ID represent?\n\n\n\n\nQuestion 3: Briefly describe TMT-labeled mass spectrometry proteomics data and explain the experimental procedure involved.\n\n\n\nTMT10-Tags and Tumor IDs\nFill in the table below by entering the corresponding TMT10-tags and Tumor IDs. Once submitted, you’ll get instant feedback on whether your input is correct.\n\n\n\n\nTMT/Plex Set\n\n\nSet 1\n\n\nSet 2\n\n\nSet 3\n\n\nSet 4\n\n\nSet 5\n\n\n\n\nTMT126\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT127N\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT127C\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT128N\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT128C\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT129N\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT129C\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT130N\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT130C\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT131\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubmit\n\n\nDownload Annotation Files\n\n\n\n\n\n\n\nQuestion 4: What is in TMT131?\n\n\n\n\nQuestion 5: What is the purpose of using this type of sample?\n\n\nNow that we better understand the workflow of the study and the content of the data, we are ready to move on to the analysis performed by FragPipe in the next section."
  },
  {
    "objectID": "develop/teachingmodule.html#analysis-of-ms-data-using-fragpipe",
    "href": "develop/teachingmodule.html#analysis-of-ms-data-using-fragpipe",
    "title": "Breast Cancer Proteomics Module",
    "section": "Analysis of MS Data Using FragPipe",
    "text": "Analysis of MS Data Using FragPipe\nIn this section of the teaching module, we will work with data from the paper. The first task is to download sample files from the paper, guided by the questions provided below:\n\n\nQuestion 6: Where can the data be found?\n\n\n\n\nQuestion 7: What is the ProteomeXChange database?\n\n\n\n\nQuestion 8: What accession code is used for the data deposited in ProteomeXChange?\n\n\nBy examining the accession code for the data deposited on ProteomeXChange, we can access and download the data using FTP.\n\n\nQuestion 9: What is FTP, and what is its functionality?\n\n\nFor downloading the data, we will use the Proteomics Sandbox Application on UCloud. This platform allows us to access the necessary storage capacity as well as the computational power required to execute this process.\nThe Proteomics Sandbox Application is a virtual environment that includes multiple software tools, including FragPipe for analyzing proteomics data.\nYou can find the Proteomics Sandbox Application on UCloud here.\nFirst, we will download the data for the sample files to be used in FragPipe. Then, we will launch FragPipe to run the first analysis of the data. Before doing so, we have some questions regarding FragPipe and its usability:\n\n\nQuestion 10: What is FragPipe, and what are its applications?\n\n\n\n\nQuestion 11: If FragPipe were not used for this part of the teaching module, which alternative software tools could be employed? Please provide a few examples.\n\n\n\n\nQuestion 12: What are the benefits of using FragPipe?\n\n\nSimple analyses in FragPipe may only require 8 GB of RAM, while large-scale or complex analyses may require 24 GB of memory or more (FragPipe Documentation), which is why we will allocate 24 GB for this exercise.\nIn UCloud, the settings should look like this:\nSCREENSHOT HERE\nBefore submitting the job, it is also recommended to create a personal folder where you can store both the data and the results generated by FragPipe. You can follow the step-by-step guide below:\nSCREENSHOT HERE\nCAUTION!!!\nMake sure to allocate the right number of hours before submitting the job. If the time runs out, the job will be canceled, and all progress will be lost. However, you can always extend the job duration if more time is required after submission.\nTime can pass quickly when working, so we recommend initially allocating 2 hours for the job. Now, we are ready to submit the job and launch the virtual environment of the Proteomics Sandbox Application."
  },
  {
    "objectID": "develop/teachingmodule.html#download-data-from-the-paper",
    "href": "develop/teachingmodule.html#download-data-from-the-paper",
    "title": "Breast Cancer Proteomics Module",
    "section": "Download Data from the Paper",
    "text": "Download Data from the Paper\nInitially, we will need to download the paper’s data. For this exercise, we will only use one sample file from each Plex Set/Pool.\nWe will use the terminal in the virtual environment for downloading the data. First, we need to update and download the necessary packages. You can do that by typing the following code:\nsudo apt-get update\nsudo apt-get install lftp\n\n\nQuestion 13: What does the code above do? Please explain its functionality and purpose.\n\n\nNow, we can access the FTP server where the data is located. You will need the server address from the correct FTP-server, which can be found on the site for the accession code XXX in ProteomeXchange, previously visited. At the bottom of the page, you will find the FTP-server address where the data is stored.\n\n\nQuestion 14: Please locate the address.\n\n\nThe address is used for accessing the data used in the study. To do so, we can use the package lftp that we just installed to access the server using the following code:\nlftp [insert the address of the FTP server here]\nlftp ftp://ftp.......\n\n\nQuestion 15: We now have access to the data stored on the FTP server. Please provide a brief description of the contents of the folder on the FTP server.\n\n\nTo download one sample file from each of the Plex Sets, you can use the following code in the terminal:\n\nCODE HERE\n\n\nQuestion 16: Please explain what the code is doing by describing the functions used.\n\n\nIf you added your own private folder to the UCloud session, you could now move the data into that folder for better management of the data you’re working with.\nNext, we can launch FragPipe, which is located on the desktop. In this tutorial, we are using FragPipe version XX.YY in the June 2024 version of the Proteomics Sandbox Application.\nNow that we have launched FragPipe, we need to configure the settings prior to running the analysis. Therefore, we have provided some guiding questions to help you set up the settings in FragPipe:\n\n\nGetting started with FragPipe\nGo to the “Workflow” tab to set up the workflow for the analysis and import the data you have just downloaded.\n\n\nQuestion 17: Which workflow should you select? HINT: How many TMT tags are listed in the table in Supplementary Data 1?\n\n\nClick ‘Load workflow’ after you have found and selected the correct workflow to be used.\nNext, add your files by clicking on “Add files” and locate them in the designated folder for your raw files that you previously created.\nNow you should relocate to the “Database” tab. Here you can either download or browse for an already preexisting database file. In this case, we will simply download the latest database file.\n\n\nQuestion 18: What is the purpose of the database file used in FragPipe, and why is it important?\n\n\n\n\nQuestion 19: Which organism should you choose when downloading the database file?\n\n\n\n\nQuestion 20: Describe the relationship between decoys and false discovery rate (FDR) by answering the following questions:\n\n\n\nWhat are decoys?\n\n\nWhy should you include decoys?\n\n\nWhat role do decoys play in estimating the FDR?\n\n\n\nNext, you can go to the MSFragger tab to adjust the parameter settings for the search and matching of the theoretical and experimental peptide spectra.\nMost of the settings used for MSFragger can be obtained from the paper NAME OF PAPER, which is referred to in the Methods and Materials section.\nWhen all settings have been obtained, MSFragger should look something like this:\n\n\nQuestion 21: What is MSFragger?\n\n\n\n\nQuestion 22: How does MSFragger operate?\n\n\n\n\nQuestion 23: Why is it essential to run MSFragger for this analysis?\n\n\nFinally, we can navigate to the “Run” tab and run the analysis. For that, we must choose an output directory for the results of the search made by FragPipe. Once you have adjusted that, you are ready to click on “Run”.\nThis process might take some time, so make sure that you still have enough hours allocated on your job on UCloud—otherwise, it will get terminated. Meanwhile, you can answer these questions:\n\n\nQuestion 24: What are your expectations regarding the output results? Consider the implications of the number of files provided for this search in your response.\n\n\n\n\nQuestion 25: Can the output from this analysis be reliably used for downstream applications given the limited number of sample files? Justify your answer.\n\n\n\n\nQuestion 26: What does it signify that the sample tissues have been fractionated as described in PAPER?\n\n\n\nOutline the fractionation process utilized.\n\n\nExplain the study design associated with this research.\n\n\nIn your opinion, will increasing the number of fractions improve proteome coverage? Justify your reasoning.\n\n\n\nWhen the run in FragPipe is done, please locate the output results and get an overview of the output.\n\n\nQuestion 27: What types of output are generated by FragPipe?\n\n\nFor the downstream analysis, we will use the output from the list of combined proteins, which we will explore further in the following section."
  },
  {
    "objectID": "develop/teachingmodule.html#further-interpretation-and-analysis-of-fragpipe-results",
    "href": "develop/teachingmodule.html#further-interpretation-and-analysis-of-fragpipe-results",
    "title": "Breast Cancer Proteomics Module",
    "section": "Further Interpretation and Analysis of FragPipe Results",
    "text": "Further Interpretation and Analysis of FragPipe Results\nFor this part, we will use output files based on a run with FragPipe using all sample files (i.e., 5x72 raw files). That file can be downloaded here???\nNow, we will look at the output from FragPipe, where we will use the file named combined_proteins.tsv. Initially, we will explore the contents of the file locally. Therefore, you should download the file from UCloud and view it locally in a file editor such as Excel.\nYou can download the file by clicking on the file in your output directory in the UCloud interface, from where you can choose to download it.\n\n\nQuestion 28: Provide a concise overview of the table’s contents. What information is represented in the rows and columns?\n\n\nFor the downstream analysis, we will use the columns containing the TMT intensities across the proteins identified.\nFor that we will use OmicsQ, which is a toolkit for quantitative proteomics. OmicsQ can be used to facilitate the processing of quantitative data from Omics type experiments. Additionally, it also serves as an entrypoint for using apps like PolySTest [SCHWAMMLE20201396] for statistical testing, VSClust for clustering and ComplexBrowser for the investigation of the behavior of protein complexes."
  },
  {
    "objectID": "develop/teachingmodule.html#study-design-and-aim",
    "href": "develop/teachingmodule.html#study-design-and-aim",
    "title": "Breast Cancer Proteomics Module",
    "section": "1. Study Design and Aim",
    "text": "1. Study Design and Aim\n1.1. What was the primary objective of the Johansson et al. study on breast cancer proteomics?\n1.2. Describe the study’s design. How were the tumor samples selected and classified? What subtypes of breast cancer were included in the analysis?"
  },
  {
    "objectID": "develop/teachingmodule.html#experimental-setup",
    "href": "develop/teachingmodule.html#experimental-setup",
    "title": "Breast Cancer Proteomics Module",
    "section": "2. Experimental Setup",
    "text": "2. Experimental Setup\n2.1. What were the main proteomic techniques used in this study to quantify proteins in breast tumors?\n2.2. Why was mass spectrometry (MS) chosen for this study?"
  },
  {
    "objectID": "develop/teachingmodule.html#data-and-analysis",
    "href": "develop/teachingmodule.html#data-and-analysis",
    "title": "Breast Cancer Proteomics Module",
    "section": "3. Data and Analysis",
    "text": "3. Data and Analysis\n3.1. The study identified nearly 10,000 proteins. What criteria were used to quantify and select proteins for analysis?\n3.2. What is the significance of integrating proteomics with other data layers such as mRNA expression, genome copy-number alterations, and single-nucleotide polymorphisms in this study?\n3.3. How did the unsupervised clustering of proteome profiles relate to the established PAM50 breast cancer subtypes?"
  },
  {
    "objectID": "develop/teachingmodule.html#key-findings",
    "href": "develop/teachingmodule.html#key-findings",
    "title": "Breast Cancer Proteomics Module",
    "section": "4. Key Findings",
    "text": "4. Key Findings\n4.1. What novel insights did this study provide about basal-like and luminal B tumors in terms of immune infiltration?\n4.2. How does the discovery of protein products from non-coding genomic regions potentially impact breast cancer immunotherapy?"
  },
  {
    "objectID": "develop/teachingmodule.html#conclusion-and-implications",
    "href": "develop/teachingmodule.html#conclusion-and-implications",
    "title": "Breast Cancer Proteomics Module",
    "section": "5. Conclusion and Implications",
    "text": "5. Conclusion and Implications\n5.1. Summarize the main findings of this study and their potential impact on breast cancer treatment and prognosis."
  },
  {
    "objectID": "develop/teachingmodule.html#study-design-and-aim-1",
    "href": "develop/teachingmodule.html#study-design-and-aim-1",
    "title": "Breast Cancer Proteomics Module",
    "section": "1. Study Design and Aim",
    "text": "1. Study Design and Aim\n1.1.\nThe primary objective of this study was to perform an in-depth, unbiased proteomic analysis of breast tumors to better understand their molecular heterogeneity. The study aimed to provide a detailed quantitative proteomic landscape of breast cancer, revealing potential prognostic markers and therapeutic targets, particularly focusing on subtypes poorly defined by previous mRNA-based methods.\nSource: Introduction, page 1\n1.2.\nThe study included 45 breast tumors, with 9 patients representing each of the five PAM50-based molecular classifications (basal-like, HER2, luminal A, luminal B, and normal-like). These tumors were selected from the Oslo2 study cohort. The classification aimed to ensure diversity and comprehensive subtype representation.\nSource: Study Design and Sample Selection, page 3"
  },
  {
    "objectID": "develop/teachingmodule.html#experimental-setup-1",
    "href": "develop/teachingmodule.html#experimental-setup-1",
    "title": "Breast Cancer Proteomics Module",
    "section": "2. Experimental Setup",
    "text": "2. Experimental Setup\n2.1.\nThe main technique used was LC-MS/MS-based protein quantification, combined with high-resolution isoelectric focusing (HiRIEF). These methods allowed for in-depth quantification of almost 10,000 proteins across the 45 tumor samples.\nSource: Methods, page 3\n2.2.\nMS was chosen because it provides high-throughput and quantitative protein measurements, essential for understanding the protein landscape of breast cancer.\nSource: Methods, page 1, 2"
  },
  {
    "objectID": "develop/teachingmodule.html#data-and-analysis-1",
    "href": "develop/teachingmodule.html#data-and-analysis-1",
    "title": "Breast Cancer Proteomics Module",
    "section": "3. Data and Analysis",
    "text": "3. Data and Analysis\n3.1.\nThe subset of proteins used for quantitative analysis was based on gene symbol-centric quantification, with a median of 12 unique peptides per protein and 24 peptide spectrum matches (PSMs) per protein. Proteins were included in the analysis only if they were quantified in all 45 tumors.\nSource: Results, page 3\n3.2.\nIntegrating proteomics with other omics data layers provided a comprehensive multi-level understanding of breast cancer biology. By combining protein data with mRNA expression, copy-number alterations, and SNPs, the study revealed correlations between different molecular levels and how these layers interact to drive tumor behavior. This integrated approach also highlighted cases where mRNA does not correlate with protein abundance, underscoring the importance of direct protein measurements.\nSource: Results, page 2\n3.3.\nThe unsupervised clustering largely recapitulated the PAM50 subtypes but showed some overlap between the luminal B and HER2 subtypes.\nSource: Results, page 4"
  },
  {
    "objectID": "develop/teachingmodule.html#key-findings-1",
    "href": "develop/teachingmodule.html#key-findings-1",
    "title": "Breast Cancer Proteomics Module",
    "section": "4. Key Findings",
    "text": "4. Key Findings\n4.1.\nThe study found that basal-like and luminal B tumors could be further subdivided based on immune component infiltration, suggesting that current classifications might be incomplete. This immune infiltration provided new prognostic markers, with implications for the development of immune-targeted therapies.\nSource: Results, page 2\n4.2.\nThe discovery of protein products from non-coding genomic regions, such as long non-coding RNAs (lncRNAs) and pseudogenes, opens up the possibility of using these proteins as tumor-specific antigens. These neoantigens could be targeted by immunotherapies, offering a new class of treatment options for breast cancer patients.\nSource: Results, page 9"
  },
  {
    "objectID": "develop/teachingmodule.html#conclusion-and-implications-1",
    "href": "develop/teachingmodule.html#conclusion-and-implications-1",
    "title": "Breast Cancer Proteomics Module",
    "section": "5. Conclusion and Implications",
    "text": "5. Conclusion and Implications\n5.1.\nThis study provided a comprehensive proteomic and proteogenomic landscape of breast cancer, identifying nearly 10,000 proteins and linking them with mRNA expression, genomic alterations, and immune signatures. It highlighted novel tumor subtypes, provided new biomarkers for prognosis, and revealed potential therapeutic targets, including tumor-specific antigens from non-coding regions. These findings may lead to more personalized treatments, particularly in targeting previously unrecognized molecular features of breast cancer.\nSource: Discussion, page 11"
  },
  {
    "objectID": "develop/keywords.html",
    "href": "develop/keywords.html",
    "title": "Clinical Proteomics",
    "section": "",
    "text": "Here’s a lit of used keywords:\n[TAGS]"
  },
  {
    "objectID": "develop/gettingstarted.html",
    "href": "develop/gettingstarted.html",
    "title": "Getting Started",
    "section": "",
    "text": "!!! note “Section Overview”\n&#128368; **Time Estimation:** 10 minutes\n\n&#128172; **Learning Objectives:**    \n    1. Launch the Proteomics Sandbox App and become proficient in using it for proteomics data analysis.  \n    2. Familiarize oneself with the software tools available within the app, such as FragPipe, MaxQuant, PDV, SearchGUI, and PeptideShaker.  \n    3. Develop skills in utilizing the Proteomics Sandbox App's lightweight clone feature, in order to reduce storage requirements while analyzing large datasets.  \n\n\nThe Proteomics Sandbox App is an excellent resource for biomedical students and non-computational researchers to learn and apply clinical proteomics. It provides a stable platform for proteomics software tools and offers a user-friendly interface. It is easy to use and does not require extensive coding knowledge. Furthermore, the app’s lightweight clone feature optimizes storage requirements when working with datasets.\n\n\nThe software available in the Proteomics Sandbox includes FragPipe, MaxQuant, PDV, SearchGUI, ThermoRawFileParser, PeptideShaker, MZmine 3, DIA-NN, and VMD. These software tools provide automated peptide and protein identification and quantification, comprehensive proteomics data analysis, visualization tools for spectral matches, a user-friendly interface for performing peptide searches, and a tool for visualizing and analyzing peptide search results. An overview table with a short description of each software tool is listed below for reference.\n\n\n\nSoftware\nDescription\n\n\n\n\nFragPipe\nAutomated peptide and protein identification and quantification using the MSFragger search engine. Supports the identification of arbitrary PTMs. Includes additional tools for post-processing and visualization of search results.\n\n\nMaxQuant\nComprehensive software suite for proteomics data analysis. Includes protein and peptide identification, quantification, and visualization of spectral matches. Features an advanced search engine; only the command-line tool is available on Linux as the GUI is incompatible.\n\n\nPDV\nVisualization tool for spectral matches, particularly those obtained from MSFragger searches. Allows users to inspect and evaluate the quality of the matches. Supports annotation and customization of plots.\n\n\nSearchGUI\nUser-friendly interface for performing peptide searches using multiple search engines (e.g., MSFragger, X!Tandem, OMSSA). Supports a wide range of search options and post-processing features.\n\n\nThermoRawFileParser\nA tool for converting Thermo Scientific RAW files to an open format mzML file that can be read by other proteomics software. Includes options for filtering, peak picking, and data conversion.\n\n\nPeptideShaker\nTool for visualizing and analyzing the results of peptide searches performed with SearchGUI. Includes features for filtering, annotation, and visualization of results. Supports integration with other proteomics databases and software.\n\n\nMZmine 3\nOpen-source software for LC-MS data processing, MZmine 3 is a complete redesign of the original MZmine toolbox. It offers a flexible, user-friendly platform with modules for the full LC-MS data analysis workflow.\n\n\nDIA-NN\nDIA-NN is a universal tool for DIA proteomics data. It features robust algorithms for reliable, large-scale experiments, emphasizing ease of use, reproducibility, and high throughput, processing up to 1000 runs per hour.\n\n\nVMD\nVisual Molecular Dynamics (VMD) is a molecular visualization program for displaying, animating, and analyzing large biomolecular systems using 3D graphics and built-in scripting. Supports various molecular dynamics simulations and bioinformatics analyses.\n\n\n\n\n\n\n!!! tip “Advantages of using the Proteomics Sandbox App” 1. Access to stable proteomics software tools. 2. User-friendly interface that does not require extensive coding knowledge. 3. Lightweight clone feature that optimizes storage requirements when working with datasets.\nThe Clinical Proteomics Sandbox is an excellent resource for biomedical students and non-computational researchers seeking to expand their knowledge and skills in clinical proteomics.\n\n\n\n\nThe Clinical Proteomics Sandbox is constantly evolving to provide an accessible platform for learning and practicing clinical proteomics data analysis. In the future, the sandbox will expand its content to include new modules such as:\n\nProtein quantification and analysis of post-translational modifications, which will provide an even more comprehensive resource for those interested in clinical proteomics.\nIntroducing mass-spectrometry imaging (MSi) for clinical specimen. Data for MS imaging is available and public clinical datasets could also be included.\nGenerate course material based on clinical proteomics data using FragPipe.\nInvestigate protein complexes.\n\nIn addition, the sandbox aims to:\n\nMake clinical proteomics data available for education and training purposes, offering students and researchers the opportunity to work with real-world clinical data and gain practical experience in analyzing and interpreting such data.\nMove into statistical and functional analysis of quantitative proteomics data and meta-analysis of clinical proteomics data.\n\nAs the sandbox continues to evolve, it will offer an invaluable resource for those seeking to enhance their knowledge and skills in clinical proteomics data analysis.\n\n\n\nThe Clinical Proteomics Sandbox App provides a stable platform for proteomics software tools and a user-friendly interface for non-computational researchers and biomedical students to learn and apply clinical proteomics. The app’s lightweight clone feature optimizes storage requirements when working with datasets. Software tools available include FragPipe, MaxQuant, PDV, SearchGUI, ThermoRawFileParser, and PeptideShaker. The Sandbox will expand its content in the future, including modules for protein quantification and analysis of post-translational modifications, and will make clinical proteomics data available for education and training purposes."
  },
  {
    "objectID": "develop/gettingstarted.html#introduction",
    "href": "develop/gettingstarted.html#introduction",
    "title": "Getting Started",
    "section": "",
    "text": "The Proteomics Sandbox App is an excellent resource for biomedical students and non-computational researchers to learn and apply clinical proteomics. It provides a stable platform for proteomics software tools and offers a user-friendly interface. It is easy to use and does not require extensive coding knowledge. Furthermore, the app’s lightweight clone feature optimizes storage requirements when working with datasets.\n\n\nThe software available in the Proteomics Sandbox includes FragPipe, MaxQuant, PDV, SearchGUI, ThermoRawFileParser, PeptideShaker, MZmine 3, DIA-NN, and VMD. These software tools provide automated peptide and protein identification and quantification, comprehensive proteomics data analysis, visualization tools for spectral matches, a user-friendly interface for performing peptide searches, and a tool for visualizing and analyzing peptide search results. An overview table with a short description of each software tool is listed below for reference.\n\n\n\nSoftware\nDescription\n\n\n\n\nFragPipe\nAutomated peptide and protein identification and quantification using the MSFragger search engine. Supports the identification of arbitrary PTMs. Includes additional tools for post-processing and visualization of search results.\n\n\nMaxQuant\nComprehensive software suite for proteomics data analysis. Includes protein and peptide identification, quantification, and visualization of spectral matches. Features an advanced search engine; only the command-line tool is available on Linux as the GUI is incompatible.\n\n\nPDV\nVisualization tool for spectral matches, particularly those obtained from MSFragger searches. Allows users to inspect and evaluate the quality of the matches. Supports annotation and customization of plots.\n\n\nSearchGUI\nUser-friendly interface for performing peptide searches using multiple search engines (e.g., MSFragger, X!Tandem, OMSSA). Supports a wide range of search options and post-processing features.\n\n\nThermoRawFileParser\nA tool for converting Thermo Scientific RAW files to an open format mzML file that can be read by other proteomics software. Includes options for filtering, peak picking, and data conversion.\n\n\nPeptideShaker\nTool for visualizing and analyzing the results of peptide searches performed with SearchGUI. Includes features for filtering, annotation, and visualization of results. Supports integration with other proteomics databases and software.\n\n\nMZmine 3\nOpen-source software for LC-MS data processing, MZmine 3 is a complete redesign of the original MZmine toolbox. It offers a flexible, user-friendly platform with modules for the full LC-MS data analysis workflow.\n\n\nDIA-NN\nDIA-NN is a universal tool for DIA proteomics data. It features robust algorithms for reliable, large-scale experiments, emphasizing ease of use, reproducibility, and high throughput, processing up to 1000 runs per hour.\n\n\nVMD\nVisual Molecular Dynamics (VMD) is a molecular visualization program for displaying, animating, and analyzing large biomolecular systems using 3D graphics and built-in scripting. Supports various molecular dynamics simulations and bioinformatics analyses.\n\n\n\n\n\n\n!!! tip “Advantages of using the Proteomics Sandbox App” 1. Access to stable proteomics software tools. 2. User-friendly interface that does not require extensive coding knowledge. 3. Lightweight clone feature that optimizes storage requirements when working with datasets.\nThe Clinical Proteomics Sandbox is an excellent resource for biomedical students and non-computational researchers seeking to expand their knowledge and skills in clinical proteomics."
  },
  {
    "objectID": "develop/gettingstarted.html#future-plans",
    "href": "develop/gettingstarted.html#future-plans",
    "title": "Getting Started",
    "section": "",
    "text": "The Clinical Proteomics Sandbox is constantly evolving to provide an accessible platform for learning and practicing clinical proteomics data analysis. In the future, the sandbox will expand its content to include new modules such as:\n\nProtein quantification and analysis of post-translational modifications, which will provide an even more comprehensive resource for those interested in clinical proteomics.\nIntroducing mass-spectrometry imaging (MSi) for clinical specimen. Data for MS imaging is available and public clinical datasets could also be included.\nGenerate course material based on clinical proteomics data using FragPipe.\nInvestigate protein complexes.\n\nIn addition, the sandbox aims to:\n\nMake clinical proteomics data available for education and training purposes, offering students and researchers the opportunity to work with real-world clinical data and gain practical experience in analyzing and interpreting such data.\nMove into statistical and functional analysis of quantitative proteomics data and meta-analysis of clinical proteomics data.\n\nAs the sandbox continues to evolve, it will offer an invaluable resource for those seeking to enhance their knowledge and skills in clinical proteomics data analysis."
  },
  {
    "objectID": "develop/gettingstarted.html#in-brief",
    "href": "develop/gettingstarted.html#in-brief",
    "title": "Getting Started",
    "section": "",
    "text": "The Clinical Proteomics Sandbox App provides a stable platform for proteomics software tools and a user-friendly interface for non-computational researchers and biomedical students to learn and apply clinical proteomics. The app’s lightweight clone feature optimizes storage requirements when working with datasets. Software tools available include FragPipe, MaxQuant, PDV, SearchGUI, ThermoRawFileParser, and PeptideShaker. The Sandbox will expand its content in the future, including modules for protein quantification and analysis of post-translational modifications, and will make clinical proteomics data available for education and training purposes."
  },
  {
    "objectID": "develop/coursematerials.html",
    "href": "develop/coursematerials.html",
    "title": "Course Materials",
    "section": "",
    "text": "This page provides access to course materials on proteomics. Please note that the page is currently under development, and more detailed course materials will be added in the future.\n\n\nAre you interested in delving deeper into the fascinating field of proteomics? Whether you are pursuing a BSc, MSc or PhD degree, you can expand your knowledge and skills in proteomics by taking advantage of the various courses available. These courses cover both experimental and computational approaches, offering a comprehensive understanding of the field.\n!!! tip “Available Proteomics Courses” If you are keen on delving deeper into proteomics, either through experimental or computational approaches, take a look at the following courses available at SDU:\n- [BMB535: Experimental Proteomics - Characterization of cellular signaling using quantitative proteomics](https://odin.sdu.dk/sitecore/index.php?a=searchfagbesk&internkode=bmb535&lang=en)  \n- [BMB542: Biomedical mass spectrometry – principles and applications](https://odin.sdu.dk/sitecore/index.php?a=searchfagbesk&internkode=bmb542&lang=en)\n- [BMB834: Protein structure, dynamics and modelling](https://odin.sdu.dk/sitecore/index.php?a=fagbesk&id=115655&lang=en&listid=)  \n- [BMB831: Biostatistics in R II](https://odin.sdu.dk/sitecore/index.php?a=fagbesk&id=123609&lang=en&listid=)  \n- [BMB210: Advanced methods in protein mass spectrometry and proteomics](https://odin.sdu.dk/sitecore/index.php?a=fagbesk&id=121176&lang=en&listid=)  \n\n\nGet started on your proteomics journey today with these exciting course offerings! The course materials listed below offer in-depth descriptions and all the necessary resources you need to succeed:\n\nAccess the powerful workshop in ColabFold on GitHub.\n\nFind comprehensive materials for Quantitative Proteomics also on GitHub.\n\n\n\n\n\nClinical proteomics data analysis course materials are currently being developed and will be accessible on the Clinical Proteomics Sandbox website in the future."
  },
  {
    "objectID": "develop/coursematerials.html#enhance-your-proteomics-knowledge",
    "href": "develop/coursematerials.html#enhance-your-proteomics-knowledge",
    "title": "Course Materials",
    "section": "",
    "text": "Are you interested in delving deeper into the fascinating field of proteomics? Whether you are pursuing a BSc, MSc or PhD degree, you can expand your knowledge and skills in proteomics by taking advantage of the various courses available. These courses cover both experimental and computational approaches, offering a comprehensive understanding of the field.\n!!! tip “Available Proteomics Courses” If you are keen on delving deeper into proteomics, either through experimental or computational approaches, take a look at the following courses available at SDU:\n- [BMB535: Experimental Proteomics - Characterization of cellular signaling using quantitative proteomics](https://odin.sdu.dk/sitecore/index.php?a=searchfagbesk&internkode=bmb535&lang=en)  \n- [BMB542: Biomedical mass spectrometry – principles and applications](https://odin.sdu.dk/sitecore/index.php?a=searchfagbesk&internkode=bmb542&lang=en)\n- [BMB834: Protein structure, dynamics and modelling](https://odin.sdu.dk/sitecore/index.php?a=fagbesk&id=115655&lang=en&listid=)  \n- [BMB831: Biostatistics in R II](https://odin.sdu.dk/sitecore/index.php?a=fagbesk&id=123609&lang=en&listid=)  \n- [BMB210: Advanced methods in protein mass spectrometry and proteomics](https://odin.sdu.dk/sitecore/index.php?a=fagbesk&id=121176&lang=en&listid=)  \n\n\nGet started on your proteomics journey today with these exciting course offerings! The course materials listed below offer in-depth descriptions and all the necessary resources you need to succeed:\n\nAccess the powerful workshop in ColabFold on GitHub.\n\nFind comprehensive materials for Quantitative Proteomics also on GitHub."
  },
  {
    "objectID": "develop/coursematerials.html#future-course-materials-on-proteomics",
    "href": "develop/coursematerials.html#future-course-materials-on-proteomics",
    "title": "Course Materials",
    "section": "",
    "text": "Clinical proteomics data analysis course materials are currently being developed and will be accessible on the Clinical Proteomics Sandbox website in the future."
  },
  {
    "objectID": "develop/colabfold.html",
    "href": "develop/colabfold.html",
    "title": "ColabFold",
    "section": "",
    "text": "!!! note “Section Overview”\n&#128368; **Time Estimation:** 4 hours\n\n&#128172; **Learning Objectives:**    \n    1. Explain the process of predicting protein structures based on amino acid sequences using the ColabFold web application.  \n    2. Utilize the ColabFold web application within the UCloud environment to perform complex computational tasks with optimal performance.  \n    3. Understand the metrics used by AlphaFold2 to predict protein structure models and how they relate to the confidence and accuracy of the predictions.  \n\n\nColabFold is a web application that allows users to predict protein structures from sequence data. The application is based on the AlphaFold2 algorithm, which is a deep learning model that predicts protein structures from sequence data. The ColabFold application is a simplified version of the AlphaFold2 algorithm, which is designed to be used by non-computational researchers. The ColabFold application is available on the Clinical Proteomics Sandbox website and can be accessed at UCloud.\n\n\nYou can access ColabFold through UCloud. This integration allows you to use the tool, but before beginning the ColabFold workshop, you need to download the workshop as a Jupyter Notebook from GitHub and upload it to your designated folder on UCloud. To initiate this process, please follow the steps below:\n:one: Log in to UCloud.\n:two: Choose a workspace that has GPU resources for optimal performance.\n:three: Access the application menu by clicking on Apps in the left-hand side menu.\n\n:three: Search for ColabFold and click on the icon for the application.\n\n:four: Choose the appropriate machine type and select a GPU, such as u2-gpu-1. The use of a single GPU is generally sufficient, though larger sequences may require additional computational power.\n\n:five: Deploy your own personal folder by selecting Folder and adjusting the path to your directory. Be sure to select the correct Workspace and change the Drive to where you want your data to be stored, if needed. Click on the folder name to select it and then click Use this folder in the upper right corner of the pop-up window.\n\n:six: Click on “Submit” and then “Open interface” on the following page.\n\n:seven: Prior to proceeding, ensure you’ve downloaded the Jupyter Notebook labeled AlphaFold2.ipynb from the Github repository. Then, upload the notebook to your ColabFold session using the left-hand menu.\n:eight: Proceed with the ColabFold workshop, which will guide you through the process of predicting protein structures based on amino acid sequences.\n\n\n\n!!! info “Advantages of using ColabFold at UCloud” 1. ColabFold at UCloud provides access to super-computing power, enabling users to perform complex computational tasks quickly and efficiently.\n2. The user-friendly interface of ColabFold and UCloud’s interactive HPC-environment make it easy for non-computational users to access and utilize the tool.\n3. Using ColabFold at UCloud can be a cost-effective solution for those who require access to super-computing power, as it eliminates the need for expensive hardware or software investments and offers a pay-per-use basis instead."
  },
  {
    "objectID": "develop/colabfold.html#introduction",
    "href": "develop/colabfold.html#introduction",
    "title": "ColabFold",
    "section": "",
    "text": "ColabFold is a web application that allows users to predict protein structures from sequence data. The application is based on the AlphaFold2 algorithm, which is a deep learning model that predicts protein structures from sequence data. The ColabFold application is a simplified version of the AlphaFold2 algorithm, which is designed to be used by non-computational researchers. The ColabFold application is available on the Clinical Proteomics Sandbox website and can be accessed at UCloud.\n\n\nYou can access ColabFold through UCloud. This integration allows you to use the tool, but before beginning the ColabFold workshop, you need to download the workshop as a Jupyter Notebook from GitHub and upload it to your designated folder on UCloud. To initiate this process, please follow the steps below:\n:one: Log in to UCloud.\n:two: Choose a workspace that has GPU resources for optimal performance.\n:three: Access the application menu by clicking on Apps in the left-hand side menu.\n\n:three: Search for ColabFold and click on the icon for the application.\n\n:four: Choose the appropriate machine type and select a GPU, such as u2-gpu-1. The use of a single GPU is generally sufficient, though larger sequences may require additional computational power.\n\n:five: Deploy your own personal folder by selecting Folder and adjusting the path to your directory. Be sure to select the correct Workspace and change the Drive to where you want your data to be stored, if needed. Click on the folder name to select it and then click Use this folder in the upper right corner of the pop-up window.\n\n:six: Click on “Submit” and then “Open interface” on the following page.\n\n:seven: Prior to proceeding, ensure you’ve downloaded the Jupyter Notebook labeled AlphaFold2.ipynb from the Github repository. Then, upload the notebook to your ColabFold session using the left-hand menu.\n:eight: Proceed with the ColabFold workshop, which will guide you through the process of predicting protein structures based on amino acid sequences.\n\n\n\n!!! info “Advantages of using ColabFold at UCloud” 1. ColabFold at UCloud provides access to super-computing power, enabling users to perform complex computational tasks quickly and efficiently.\n2. The user-friendly interface of ColabFold and UCloud’s interactive HPC-environment make it easy for non-computational users to access and utilize the tool.\n3. Using ColabFold at UCloud can be a cost-effective solution for those who require access to super-computing power, as it eliminates the need for expensive hardware or software investments and offers a pay-per-use basis instead."
  },
  {
    "objectID": "develop/contributors.html",
    "href": "develop/contributors.html",
    "title": "Clinical Proteomics",
    "section": "",
    "text": "The Proteomics Sandbox application has been developed with contributions from:\nJacob Fredegaard Hansen :custom-orcid: :simple-github: :simple-linkedin:  Ole Nørregaard Jensen :custom-orcid: :simple-linkedin:  Veit Stefan Schwämmle :custom-orcid: :simple-github: :simple-linkedin:"
  },
  {
    "objectID": "develop/fragpipe.html",
    "href": "develop/fragpipe.html",
    "title": "FragPipe",
    "section": "",
    "text": "Analyzing Clinical Proteomics Data Using FragPipe\n!!! note “Section Overview”\n&#128368; **Time Estimation:** 4-6 hours\n\n&#128172; **Learning Objectives:**    \n    1. Understand the principles of mass spectrometry-based proteomics and how it can be used to study clinical samples.  \n    2. Learn how to use FragPipe to process and analyze clinical proteomics data, including data preprocessing, quality control, and statistical analysis.  \n    3. Gain hands-on experience in interpreting FragPipe outputs and using them to generate biological insights from clinical proteomics data.  \nThis workshop is designed for biomedical students who want to learn how to analyze clinical proteomics data using FragPipe. The workshop will cover the basic principles of mass spectrometry-based proteomics and its applications in clinical research. Participants will learn how to use FragPipe to process and analyze clinical proteomics data, including data preprocessing, quality control, and statistical analysis. The workshop will also provide hands-on experience in interpreting FragPipe outputs and using them to generate biological insights from clinical proteomics data. By the end of the workshop, participants will have a comprehensive understanding of how to use FragPipe to analyze clinical proteomics data and gain skills that can be applied in their future research."
  },
  {
    "objectID": "develop/index.html",
    "href": "develop/index.html",
    "title": "Clinical Proteomics",
    "section": "",
    "text": "Updated: 2024-17-06\nDiscover the world of proteomics with the Clinical Proteomics module of the Sandbox, offering the Proteomics Sandbox app on UCloud - an accessible resource for biomedical students and non-computational researchers. With a user-friendly interface and a lightweight clone feature, the app is perfect for those without extensive coding knowledge, providing a stable platform for proteomics software tools. You can also learn to predict protein structures based on sequence data with the independent ColabFold workshop, available on UCloud. This hands-on experience offers insights into the exciting field of proteomics analysis and is accessible for all UCloud-users.\nNew course materials are being developed constantly to enhance your education and training in clinical proteomics data analysis. Stay tuned!\n!!! danger “Disclaimer” Currently, the educational material on proteomics is only available at UCloud, making it only accessible for UCloud-users.\n[cards cols=“4”(./develop/cards/cards.yaml)]\n!!! warning “Requirements” - Access to UCloud and sufficient resources to run the application - Basic computational knowledge, including familiarity with the UCloud environment - Familiarity with proteomics analysis techniques"
  },
  {
    "objectID": "develop/index.html#learning-clinical-proteomics-with-the-sandbox",
    "href": "develop/index.html#learning-clinical-proteomics-with-the-sandbox",
    "title": "Clinical Proteomics",
    "section": "Learning Clinical Proteomics with the Sandbox",
    "text": "Learning Clinical Proteomics with the Sandbox\nThe Clinical Proteomics Module offers a comprehensive resource for learning and practicing clinical proteomics data analysis. The module consists of the following components:\n\nThe Proteomics Sandbox app, which is a virtual machine with software readily available for clinical proteomics data analysis.\n\nColabFold workshop, which is an independent teaching material for learning to predict protein structures from sequence data based on AlphaFold.\n\nIn the future, additional course materials will be made available to provide comprehensive teaching and education in clinical proteomics. With the Clinical Proteomics Module, students and researchers have the opportunity to work with real-world clinical data, gain practical experience in analyzing and interpreting such data, and enhance their knowledge and skills in clinical proteomics data analysis.\nExplore the various sections of the proteomics module by clicking on the tabs above."
  },
  {
    "objectID": "develop/setup.html",
    "href": "develop/setup.html",
    "title": "Setup",
    "section": "",
    "text": "!!! note “Section Overview”\n&#128368; **Total Time Estimation:** 10 minutes\n\n&#128172; **Learning Objectives:**    \n    1. Launch the Proteomics Sandbox App and become proficient in using it for proteomics data analysis.  \n    2. Deploy your own data in the Proteomics Sandbox app.   \n\n\nBelow are step-by-step instructions on how to launch the Proteomics Sandbox application in UCloud.\n:one: Navigate to the workspace where your data is located.\n:two: Access the application menu by clicking on Apps in the left-hand side menu.\n\n:three: Search for Proteomics Sandbox and click on the icon for the application.\n\n:four: Select your desired number of resources under Machine type. Remember, larger datasets will require more resources.\n\n:five: Deploy your data by selecting Folder and adjusting the path to your files. Be sure to select the correct Workspace and change the Drive to where your data is located. Click on the folder name to select it and then click Use this folder in the upper right corner of the pop-up window.\n\n:six: Once you have deployed your data, you are ready to launch the application. Click on Submit to the right of the screen and then click Open interface in the upper right corner of the following page to start using the Proteomics Sandbox application.\n\nCongratulations! You’re now ready to dive into the world of clinical proteomics and perform various analyses with the user-friendly Proteomics Sandbox app. For more detailed instructions on how to use the software available in the app, check out the official documentation for the software linked in the overview table.\n!!! danger “Important Warning” 1. When working within the Proteomics Sandbox application, it is crucial to ensure that all your work is saved in the designated ‘work’ directory. Failure to do so may result in permanent loss of your work when the session ends or expires.\n2. It is imperative to keep track of the time allocated for your UCloud job. Upon expiry, the session will terminate automatically, resulting in loss of unsaved work. It is possible to extend the number of hours for your session after it has commenced."
  },
  {
    "objectID": "develop/setup.html#launch-the-proteomics-sandbox-application-in-ucloud",
    "href": "develop/setup.html#launch-the-proteomics-sandbox-application-in-ucloud",
    "title": "Setup",
    "section": "",
    "text": "Below are step-by-step instructions on how to launch the Proteomics Sandbox application in UCloud.\n:one: Navigate to the workspace where your data is located.\n:two: Access the application menu by clicking on Apps in the left-hand side menu.\n\n:three: Search for Proteomics Sandbox and click on the icon for the application.\n\n:four: Select your desired number of resources under Machine type. Remember, larger datasets will require more resources.\n\n:five: Deploy your data by selecting Folder and adjusting the path to your files. Be sure to select the correct Workspace and change the Drive to where your data is located. Click on the folder name to select it and then click Use this folder in the upper right corner of the pop-up window.\n\n:six: Once you have deployed your data, you are ready to launch the application. Click on Submit to the right of the screen and then click Open interface in the upper right corner of the following page to start using the Proteomics Sandbox application.\n\nCongratulations! You’re now ready to dive into the world of clinical proteomics and perform various analyses with the user-friendly Proteomics Sandbox app. For more detailed instructions on how to use the software available in the app, check out the official documentation for the software linked in the overview table.\n!!! danger “Important Warning” 1. When working within the Proteomics Sandbox application, it is crucial to ensure that all your work is saved in the designated ‘work’ directory. Failure to do so may result in permanent loss of your work when the session ends or expires.\n2. It is imperative to keep track of the time allocated for your UCloud job. Upon expiry, the session will terminate automatically, resulting in loss of unsaved work. It is possible to extend the number of hours for your session after it has commenced."
  },
  {
    "objectID": "develop/teachingmodule.html#persistent-text-input",
    "href": "develop/teachingmodule.html#persistent-text-input",
    "title": "Breast Cancer Proteomics Module",
    "section": "Persistent Text Input",
    "text": "Persistent Text Input\nType something in the box below. Your input will persist even after you refresh the page.\n\n\n\nSupplementary Data\nBefore we proceed and download the data available from the paper, we must first delve into some of the details in Supplementary Data 1. This is a large table containing the quantitative proteome data from the Oslo2 breast cancer cohort, which includes 45 subgroups of cancer tumors and relates to Figures 1-6 in the paper.\nTo better understand the supplementary data, we have prepared guiding questions to aid in interpreting the table. You can find the supplementary data in the paper here.\n\nGive a short description of what the table contains.\n\n\nWhat does the tumor ID indicate?\n\n\nProvide a brief description of TMT-labelled mass spectrometry proteomics data and how it is experimentally executed.\n\n\nTMT10-Tags and Tumor IDs\nFill in the table below by entering the corresponding TMT10-tags and Tumor IDs. Once submitted, you’ll get instant feedback on whether your input is correct.\n\n\n\n\nTMT/Plex Set\n\n\nSet 1\n\n\nSet 2\n\n\nSet 3\n\n\nSet 4\n\n\nSet 5\n\n\n\n\nTMT126\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT127N\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT127C\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT128N\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT128C\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT129N\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT129C\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT130N\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT130C\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTMT131\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubmit\n\n\n\n\n\n\n\nWhat is in TMT131?\n\n\n\nWhat is the purpose of having such a sample?\n\nNow that we better understand the workflow of the study and the content of the data, we are ready to move on to the analysis performed by FragPipe in the next section."
  },
  {
    "objectID": "develop/teachingmodule.html#course-assignment",
    "href": "develop/teachingmodule.html#course-assignment",
    "title": "Breast Cancer Proteomics Module",
    "section": "Course Assignment",
    "text": "Course Assignment\nIn this assignment, you will be answering the following questions. Your input will be saved automatically, and you can download your answers as a PDF when you’re ready to submit.\n\nQuestion 1: Describe the central dogma of molecular biology.\n\n\n\nQuestion 2: Explain how mass spectrometry is used in proteomics.\n\n\n\nQuestion 3: Write a short code example in R or Python to visualize data.\n\n\nDownload Your Answers as PDF"
  },
  {
    "objectID": "develop/teachingmodule.html#module-assignment",
    "href": "develop/teachingmodule.html#module-assignment",
    "title": "Breast Cancer Proteomics Module",
    "section": "",
    "text": "In this module, you will be working through questions based on the analysis steps using FragPipe for proteomics data. Your answers will be saved automatically, and you can download them as a PDF when finished.\n\n!!! note “Section Overview”\n&#128368; **Total Time Estimation:** 8 hours\n\n&#128172; **Learning Objectives:**    \n    1. Understand the workflow of the study. &lt;br&gt;\n    2. Retrieve and understand the study design and data from selected papers. &lt;br&gt;\n    3. Download and preprocess proteomics data using FragPipe. &lt;br&gt;\n    4. Set up and use FragPipe for TMT-labeled MS data analysis. &lt;br&gt;\n    5. Create accurate annotation files for data analysis."
  },
  {
    "objectID": "develop/teachingmodule.html#personal-details",
    "href": "develop/teachingmodule.html#personal-details",
    "title": "Breast Cancer Proteomics Module",
    "section": "Personal Details",
    "text": "Personal Details\nName:\n\n\nEmail:\n\n\nCourse/Program:\n\n\nDate:\n\n\n\nDownload Your Answers as PDF"
  }
]